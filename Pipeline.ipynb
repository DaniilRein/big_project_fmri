{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import image, input_data, plotting\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.plotting import plot_stat_map\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial information from original 'README' file:\n",
    "\n",
    "onset(sec) duration(sec) emotion\n",
    "\n",
    "0 30 calm\n",
    "\n",
    "30 30 white noise\n",
    "\n",
    "60 30 afraid\n",
    "\n",
    "90 30 white noise\n",
    "\n",
    "120 30 delighted\n",
    "\n",
    "150 30 white noise\n",
    "\n",
    "180 30 depressed\n",
    "\n",
    "210 30 white noise\n",
    "\n",
    "240 30 excited\n",
    "\n",
    "270 30 white noise\n",
    "\n",
    "300 30 delighted\n",
    "\n",
    "330 30 white noise\n",
    "\n",
    "360 30 depressed\n",
    "\n",
    "390 30 white noise\n",
    "\n",
    "420 30 calm\n",
    "\n",
    "450 30 white noise\n",
    "\n",
    "480 30 excited\n",
    "\n",
    "510 30 white noise\n",
    "\n",
    "540 30 afraid\n",
    "\n",
    "570 30 white noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pandas DataFrame method to segment the data.\n",
    "def create_events_df():\n",
    "    \"\"\"Create events DataFrame(Pandas) from the trial segments information\"\"\"\n",
    "    events = pd.DataFrame({\n",
    "        'onset': [0, 60, 120, 180, 240, 300, 360, 420, 480, 540],\n",
    "        'duration': [30] * 10,\n",
    "        'emotion': ['calm', 'afraid', 'delighted', 'depressed', \n",
    "                   'excited', 'delighted', 'depressed', 'calm', \n",
    "                   'excited', 'afraid']\n",
    "    })\n",
    "    # Create trial_type column grouping emotions by valence - into broader groups.\n",
    "    valence_mapping = {\n",
    "        'calm': 'neutral',\n",
    "        'afraid': 'negative',\n",
    "        'delighted': 'positive',\n",
    "        'depressed': 'negative',\n",
    "        'excited': 'positive'\n",
    "    }\n",
    "    # map valence type in addition to original emotion categories.\n",
    "    # Doing so will make data access during analysis easier.\n",
    "    events['trial_type'] = events['emotion'].map(valence_mapping)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(subject_id):\n",
    "    \"\"\"Load and prepare fMRI data for a single subject\"\"\"\n",
    "    # Construct file paths\n",
    "    func_file = f'sub-{subject_id}/func/sub-{subject_id}_task-fe_bold.nii'\n",
    "    anat_file = f'sub-{subject_id}/anat/sub-{subject_id}_T1w.nii'\n",
    "    \n",
    "    # Load the functional and anatomical images\n",
    "    func_img = image.load_img(func_file)\n",
    "    anat_img = image.load_img(anat_file)\n",
    "    \n",
    "    return func_img, anat_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(anat_img):\n",
    "    \"\"\"Create ROI masks for emotional processing regions\"\"\"\n",
    "    from nilearn.datasets import fetch_atlas_harvard_oxford\n",
    "    \n",
    "    # Fetch both cortical and subcortical Harvard-Oxford atlases\n",
    "    cortical = fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')\n",
    "    subcortical = fetch_atlas_harvard_oxford('sub-maxprob-thr25-2mm')\n",
    "    \n",
    "    # Create masks for regions of interest\n",
    "    roi_masks = {\n",
    "        # Subcortical regions\n",
    "        'amygdala_left': image.math_img('img == 2', img=subcortical.maps),    \n",
    "        'amygdala_right': image.math_img('img == 3', img=subcortical.maps),   \n",
    "        'hippocampus_left': image.math_img('img == 4', img=subcortical.maps), \n",
    "        'hippocampus_right': image.math_img('img == 5', img=subcortical.maps),\n",
    "        \n",
    "        # Cortical regions\n",
    "        'acc': image.math_img('img == 25', img=cortical.maps),                \n",
    "        'vmpfc': image.math_img('img == 27', img=cortical.maps),             \n",
    "        'dlpfc_left': image.math_img('img == 3', img=cortical.maps),         \n",
    "        'dlpfc_right': image.math_img('img == 4', img=cortical.maps),        \n",
    "        'parietal_left': image.math_img('np.logical_or(img == 9, img == 10)', img=cortical.maps),  \n",
    "        'parietal_right': image.math_img('np.logical_or(img == 11, img == 12)', img=cortical.maps) \n",
    "    }\n",
    "    \n",
    "    # Create bilateral masks\n",
    "    bilateral_pairs = [\n",
    "        ('amygdala', 'amygdala_left', 'amygdala_right'),\n",
    "        ('hippocampus', 'hippocampus_left', 'hippocampus_right'),\n",
    "        ('dlpfc', 'dlpfc_left', 'dlpfc_right'),\n",
    "        ('parietal', 'parietal_left', 'parietal_right')\n",
    "    ]\n",
    "    \n",
    "    for name, left, right in bilateral_pairs:\n",
    "        roi_masks[f'{name}_bilateral'] = image.math_img(\n",
    "            \"img1 + img2\", \n",
    "            img1=roi_masks[left], \n",
    "            img2=roi_masks[right]\n",
    "        )\n",
    "    \n",
    "    return roi_masks, cortical, subcortical\n",
    "\n",
    "def verify_roi_masks(roi_masks, anat_img, output_dir='roi_verification'):\n",
    "    \"\"\"\n",
    "    Create visualization plots to verify ROI mask locations\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    roi_masks : dict\n",
    "        Dictionary containing the ROI mask images\n",
    "    anat_img : Nifti1Image\n",
    "        Anatomical reference image\n",
    "    output_dir : str\n",
    "        Directory to save the verification plots\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from nilearn import plotting\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Set up the MNI template for background\n",
    "    from nilearn.datasets import load_mni152_template\n",
    "    template = load_mni152_template()\n",
    "    \n",
    "    # Color mapping for different types of ROIs\n",
    "    colors = {\n",
    "        'amygdala': 'red',\n",
    "        'hippocampus': 'blue',\n",
    "        'acc': 'green',\n",
    "        'vmpfc': 'purple',\n",
    "        'dlpfc': 'orange',\n",
    "        'parietal': 'yellow'\n",
    "    }\n",
    "    \n",
    "    # Create individual ROI plots\n",
    "    for roi_name, roi_mask in roi_masks.items():\n",
    "        print(f\"Creating visualization for {roi_name}...\")\n",
    "        \n",
    "        # Create figure with multiple views\n",
    "        fig = plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Sagittal view\n",
    "        ax1 = plt.subplot(131)\n",
    "        display = plotting.plot_roi(\n",
    "            roi_mask, \n",
    "            template,\n",
    "            display_mode='x',\n",
    "            cut_coords=3,\n",
    "            title=f'{roi_name} - Sagittal',\n",
    "            axes=ax1\n",
    "        )\n",
    "        \n",
    "        # Coronal view\n",
    "        ax2 = plt.subplot(132)\n",
    "        display = plotting.plot_roi(\n",
    "            roi_mask,\n",
    "            template,\n",
    "            display_mode='y',\n",
    "            cut_coords=3,\n",
    "            title=f'{roi_name} - Coronal',\n",
    "            axes=ax2\n",
    "        )\n",
    "        \n",
    "        # Axial view\n",
    "        ax3 = plt.subplot(133)\n",
    "        display = plotting.plot_roi(\n",
    "            roi_mask,\n",
    "            template,\n",
    "            display_mode='z',\n",
    "            cut_coords=3,\n",
    "            title=f'{roi_name} - Axial',\n",
    "            axes=ax3\n",
    "        )\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'{roi_name}_verification.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    # Create a summary plot with all bilateral ROIs\n",
    "    print(\"Creating summary visualization...\")\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Get all bilateral ROIs\n",
    "    bilateral_rois = {k: v for k, v in roi_masks.items() if 'bilateral' in k}\n",
    "    \n",
    "    # Create multi-ROI display\n",
    "    displays = []\n",
    "    for view, ax, title in zip(['x', 'y', 'z'], [ax1, ax2, ax3], \n",
    "                              ['Sagittal', 'Coronal', 'Axial']):\n",
    "        display = plotting.plot_roi(\n",
    "            template,\n",
    "            template,\n",
    "            display_mode=view,\n",
    "            cut_coords=1,\n",
    "            title=f'All ROIs - {title}',\n",
    "            axes=ax\n",
    "        )\n",
    "        displays.append(display)\n",
    "        \n",
    "        # Add each ROI with a different color\n",
    "        for roi_name, roi_mask in bilateral_rois.items():\n",
    "            base_name = roi_name.split('_')[0]\n",
    "            if base_name in colors:\n",
    "                display.add_overlay(roi_mask, cmap=plotting.cm.alpha_cmap(colors[base_name]))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'all_rois_summary.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Previous main code...\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Rest of the analysis pipeline...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_subject_analysis(subject_id, events_df, roi_masks):\n",
    "    \"\"\"Perform first-level analysis for a single subject\"\"\"\n",
    "    # Load subject data\n",
    "    func_img, anat_img = load_and_prepare_data(subject_id)\n",
    "    \n",
    "    # Initialize FirstLevelModel\n",
    "    model = FirstLevelModel(\n",
    "        t_r=2.0,  # Replace with actual TR\n",
    "        noise_model='ar1',\n",
    "        standardize=True,\n",
    "        hrf_model='spm',\n",
    "        drift_model='cosine'\n",
    "    )\n",
    "    \n",
    "    # Fit the GLM\n",
    "    model.fit(func_img, events_df)\n",
    "    \n",
    "    # Create contrasts\n",
    "    contrasts = {\n",
    "        'positive_vs_neutral': 'positive - neutral',\n",
    "        'negative_vs_neutral': 'negative - neutral',\n",
    "        'positive_vs_negative': 'positive - negative'\n",
    "    }\n",
    "    \n",
    "    # Compute contrast maps\n",
    "    contrast_maps = {}\n",
    "    for contrast_id, contrast_def in contrasts.items():\n",
    "        contrast_maps[contrast_id] = model.compute_contrast(contrast_def)\n",
    "    \n",
    "    # Extract ROI signals\n",
    "    roi_signals = {}\n",
    "    for roi_name, roi_mask in roi_masks.items():\n",
    "        masker = input_data.NiftiMasker(mask_img=roi_mask)\n",
    "        roi_signals[roi_name] = masker.fit_transform(func_img)\n",
    "    \n",
    "    return contrast_maps, roi_signals\n",
    "\n",
    "def group_analysis(all_subject_contrasts):\n",
    "    \"\"\"Perform group-level analysis\"\"\"\n",
    "    from nilearn.glm import second_level\n",
    "    \n",
    "    # Initialize second-level model\n",
    "    group_model = second_level.SecondLevelModel()\n",
    "    \n",
    "    # Perform group analysis for each contrast\n",
    "    group_results = {}\n",
    "    for contrast_id in all_subject_contrasts[0].keys():\n",
    "        contrast_maps = [subj_contrasts[contrast_id] \n",
    "                        for subj_contrasts in all_subject_contrasts]\n",
    "        group_results[contrast_id] = group_model.fit(contrast_maps).compute_contrast()\n",
    "    \n",
    "    return group_results\n",
    "\n",
    "def plot_results(group_results, output_dir):\n",
    "    \"\"\"Plot and save group-level results\"\"\"\n",
    "    for contrast_id, stat_map in group_results.items():\n",
    "        display = plotting.plot_stat_map(\n",
    "            stat_map,\n",
    "            threshold=3.0,  # Adjust threshold as needed\n",
    "            title=contrast_id\n",
    "        )\n",
    "        plt.savefig(f'{output_dir}/{contrast_id}_group_map.png')\n",
    "        plt.close()\n",
    "\n",
    "def main():\n",
    "    # Parameters\n",
    "    n_subjects = 40\n",
    "    output_dir = 'results'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create events DataFrame\n",
    "    events_df = create_events_df()\n",
    "    \n",
    "    # Initialize storage for all subjects' results\n",
    "    all_subject_contrasts = []\n",
    "    all_subject_roi_signals = []\n",
    "    \n",
    "    # Add ROI verification after creating masks\n",
    "    roi_masks, cortical, subcortical = create_masks(anat_img)\n",
    "    verify_roi_masks(roi_masks, anat_img)\n",
    "    \n",
    "    # Single subject analysis\n",
    "    for subject_id in range(1, n_subjects + 1):\n",
    "        subject_id_str = f'{subject_id:02d}'\n",
    "        print(f'Processing subject {subject_id_str}...')\n",
    "        \n",
    "        contrasts, roi_signals = single_subject_analysis(\n",
    "            subject_id_str, events_df, roi_masks\n",
    "        )\n",
    "        \n",
    "        all_subject_contrasts.append(contrasts)\n",
    "        all_subject_roi_signals.append(roi_signals)\n",
    "    \n",
    "    # Group analysis\n",
    "    group_results = group_analysis(all_subject_contrasts)\n",
    "    \n",
    "    # Plot results\n",
    "    plot_results(group_results, output_dir)\n",
    "    \n",
    "    # Save results\n",
    "    # Add code to save numerical results, statistics, etc.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
